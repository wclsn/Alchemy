{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Initialize the traced repo\n",
    "We need to trace the Mathlib first so that we can interact with theorems within it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from lean_dojo import LeanGitRepo, trace, Dojo, Theorem, LeanError, TacticState, data_extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "repo = LeanGitRepo(\n",
    "    \"https://github.com/leanprover-community/mathlib4\",\n",
    "    \"3c307701fa7e9acbdc0680d7f3b9c9fed9081740\"   # We use this commit in our paper\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cache_path = \"./data/candidate_theorems.pickle\"\n",
    "if not os.path.exists(cache_path):\n",
    "    traced_repo = trace(repo)\n",
    "    candidate_theorems = [thm for thm in traced_repo.get_traced_theorems() if not thm.repo.is_lean4]\n",
    "    pickle.dump(candidate_theorems, open(cache_path, \"wb\"))\n",
    "else:\n",
    "    candidate_theorems = pickle.load(open(cache_path, \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2024-11-26 13:45:29.898\u001b[0m | \u001b[33m\u001b[1mWARNING \u001b[0m | \u001b[36mlean_dojo.interaction.dojo\u001b[0m:\u001b[36m__init__\u001b[0m:\u001b[36m162\u001b[0m - \u001b[33m\u001b[1mUsing Lean 4 without a hard timeout may hang indefinitely.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# initialize the dojo env for a target theorem\n",
    "# e.g. the demo theorem in the Fig.1 of our paper\n",
    "demo_path = \"./data/demo_theorem.pickle\"  # we provide a cached demo theorems\n",
    "demo_theorem = pickle.load(open(demo_path, \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize the dojo env\n",
    "demo_name = demo_theorem.theorem.full_name\n",
    "file_path = demo_theorem.theorem.file_path\n",
    "theorem = Theorem(repo, file_path, demo_name)\n",
    "cwd = os.getcwd()\n",
    "dojo, state_0 = Dojo(theorem).__enter__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "theorem Nat.disjoint_divisors_filter_isPrimePow {a b : ℕ} (hab : a.Coprime b) :\n",
      "    Disjoint (a.divisors.filter IsPrimePow) (b.divisors.filter IsPrimePow) := by\n",
      "  simp only [Finset.disjoint_left, Finset.mem_filter, and_imp, Nat.mem_divisors, not_and]\n",
      "  rintro n han _ha hn hbn _hb -\n",
      "  exact hn.ne_one (Nat.eq_one_of_dvd_coprimes hab han hbn)\n"
     ]
    }
   ],
   "source": [
    "ast = demo_theorem.ast\n",
    "print(ast.lean_file[ast.start:ast.end])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Find Invocable Theorems\n",
    "We find the invocable theorems by running specific tactics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(cwd) # The initialization of dojo will change the current working directory, so we need to change it back\n",
    "import tqdm\n",
    "from _parse import extract_id_decl_proof, parse_hypothesis\n",
    "from _logic import get_rw_insts, get_apply_insts\n",
    "from _utils import load_jsonl, save_jsonl\n",
    "from lean_dojo.interaction.dojo import DojoHardTimeoutError"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**To check whether a specific theorem is invocable**\n",
    "1. Get the statement and hypothesis of the demo theorem. \n",
    "2. Construct the tactics that should be run.\n",
    "3. Run the tactic and check the returning messgae."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = extract_id_decl_proof(demo_theorem)\n",
    "statement_node = nodes[1]\n",
    "hypothesis = parse_hypothesis(statement_node)\n",
    "hypo_names, _, hypo_strs = hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rw [Nat.coprime_iff_isRelPrime]', 'rw [←Nat.coprime_iff_isRelPrime]', 'rw [Nat.coprime_iff_isRelPrime] at hab', 'rw [←Nat.coprime_iff_isRelPrime] at hab']\n",
      "--------------------\n",
      "R : Type u_1\n",
      "inst✝ : CommMonoidWithZero R\n",
      "n p : R\n",
      "k a b : ℕ\n",
      "hab : Coprime a b\n",
      "⊢ Disjoint (Finset.filter IsPrimePow (divisors a)) (Finset.filter IsPrimePow (divisors b))\n",
      "--------------------\n",
      "R : Type u_1\n",
      "inst✝ : CommMonoidWithZero R\n",
      "n p : R\n",
      "k a b : ℕ\n",
      "hab : IsRelPrime a b\n",
      "⊢ Disjoint (Finset.filter IsPrimePow (divisors a)) (Finset.filter IsPrimePow (divisors b))\n"
     ]
    }
   ],
   "source": [
    "# rw example\n",
    "p_t_name = \"Nat.coprime_iff_isRelPrime\"\n",
    "rw_insts = get_rw_insts(p_t_name, hypo_names)\n",
    "print(rw_insts)\n",
    "assert rw_insts[2] == 'rw [Nat.coprime_iff_isRelPrime] at hab'\n",
    "next_state = dojo.run_tac(state_0, rw_insts[2])\n",
    "print(\"-\"*20)\n",
    "print(state_0.pp)\n",
    "print(\"-\"*20)\n",
    "print(next_state.pp) # the hypothesis is mutated (invocable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['have hab : a.Coprime b := by apply Nat.coprime_of_mul_modEq_one']\n",
      "--------------------\n",
      "R : Type u_1\n",
      "inst✝ : CommMonoidWithZero R\n",
      "n p : R\n",
      "k a b : ℕ\n",
      "hab : Coprime a b\n",
      "⊢ Disjoint (Finset.filter IsPrimePow (divisors a)) (Finset.filter IsPrimePow (divisors b))\n",
      "--------------------\n",
      "unsolved goals\n",
      "case h\n",
      "R : Type u_1\n",
      "inst✝ : CommMonoidWithZero R\n",
      "n p : R\n",
      "k a b : ℕ\n",
      "hab : Coprime a b\n",
      "⊢ a * ?b ≡ 1 [MOD b]\n",
      "\n",
      "case b\n",
      "R : Type u_1\n",
      "inst✝ : CommMonoidWithZero R\n",
      "n p : R\n",
      "k a b : ℕ\n",
      "hab : Coprime a b\n",
      "⊢ ℕ\n"
     ]
    }
   ],
   "source": [
    "# apply example\n",
    "p_t_name = \"Nat.coprime_of_mul_modEq_one\"\n",
    "apply_insts = get_apply_insts(p_t_name, hypo_strs)\n",
    "print(apply_insts)\n",
    "assert apply_insts[0] == 'have hab : a.Coprime b := by apply Nat.coprime_of_mul_modEq_one'\n",
    "next_state = dojo.run_tac(state_0, apply_insts[0])\n",
    "print(\"-\"*20)\n",
    "print(state_0.pp)\n",
    "print(\"-\"*20)\n",
    "print(next_state.error) # produce new unsolved subgoals (invocable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We implement the logic for finding new theorems in one api:\n",
    "\n",
    "- **get_invocable_theorems_with_dojo**\n",
    "\n",
    "*In practice, to support data-synthesis on multiple cpus, we run the data_generator.py on each cpu node.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from _logic import get_invocable_theorems_with_dojo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking invocable theorems:   3%|▎         | 3947/116695 [00:35<15:36, 120.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Std.Tactic.Ext.$extName\n",
      "Std.Tactic.Ext.$extIffName\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking invocable theorems:  45%|████▌     | 52802/116695 [06:51<07:15, 146.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lean.Elab.Command.$n_def\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking invocable theorems: 100%|██████████| 116695/116695 [14:49<00:00, 131.16it/s]\n"
     ]
    }
   ],
   "source": [
    "# find invocable theorems using apply\n",
    "possibly_invocable_theorems = candidate_theorems\n",
    "rw_theorems = get_invocable_theorems_with_dojo(\n",
    "    demo_theorem,dojo,state_0, possibly_invocable_theorems, mode=\"rw\"\n",
    ")\n",
    "save_jsonl(rw_theorems[1], \"./outputs/rw_invocable_theorems_demo.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking invocable theorems:   3%|▎         | 3966/116695 [00:14<05:29, 342.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Std.Tactic.Ext.$extName\n",
      "Std.Tactic.Ext.$extIffName\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking invocable theorems:  46%|████▌     | 53099/116695 [01:15<00:46, 1357.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lean.Elab.Command.$n_def\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Checking invocable theorems: 100%|██████████| 116695/116695 [02:18<00:00, 840.47it/s] \n"
     ]
    }
   ],
   "source": [
    "apply_theorems = get_invocable_theorems_with_dojo(\n",
    "    demo_theorem,dojo,state_0, possibly_invocable_theorems, mode=\"apply\"\n",
    ")\n",
    "save_jsonl(apply_theorems[1], \"./outputs/apply_invocable_theorems_demo.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Mutate and Verify the Original Theorems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Example\n",
    "We implement the process to mutate the target theorem for an invocable theorem into two apis:\n",
    "- **modify_theorem_rw**\n",
    "- **modify_theorem_apply**\n",
    "\n",
    "What should be noted is that implementations of these two apis are not perfect which can be further improved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(cwd)\n",
    "from _modify import modify_theorem_rw, modify_theorem_apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****************************************rw variant****************************************\n",
      "example {a b : ℕ} (hab : IsRelPrime a b) :\n",
      "    Disjoint (a.divisors.filter IsPrimePow) (b.divisors.filter IsPrimePow):= by\n",
      "  have hab : a.Coprime b := by rw [←Nat.coprime_iff_isRelPrime] at hab;exact hab\n",
      "  simp only [Finset.disjoint_left, Finset.mem_filter, and_imp, Nat.mem_divisors, not_and]\n",
      "  rintro n han _ha hn hbn _hb -\n",
      "  exact hn.ne_one (Nat.eq_one_of_dvd_coprimes hab han hbn)\n",
      "****************************************apply variant****************************************\n",
      "example {a b : ℕ} (g : ℕ) (h : a * g ≡ 1 [MOD b]) :\n",
      "    Disjoint (a.divisors.filter IsPrimePow) (b.divisors.filter IsPrimePow):= by\n",
      "  have hab : a.Coprime b := by apply Nat.coprime_of_mul_modEq_one<;> assumption\n",
      "  simp only [Finset.disjoint_left, Finset.mem_filter, and_imp, Nat.mem_divisors, not_and]\n",
      "  rintro n han _ha hn hbn _hb -\n",
      "  exact hn.ne_one (Nat.eq_one_of_dvd_coprimes hab han hbn)\n"
     ]
    }
   ],
   "source": [
    "# For example\n",
    "rw_invocable_inst = {\n",
    "    \"init_state\": \"R : Type u_1\\ninst✝ : CommMonoidWithZero R\\nn p : R\\nk a b : ℕ\\nhab : Coprime a b\\n⊢ Disjoint (Finset.filter IsPrimePow (divisors a)) (Finset.filter IsPrimePow (divisors b))\",\n",
    "    \"rule\": \"rw [Nat.coprime_iff_isRelPrime] at hab\",\n",
    "    \"next_state\": \"R : Type u_1\\ninst✝ : CommMonoidWithZero R\\nn p : R\\nk a b : ℕ\\nhab : IsRelPrime a b\\n⊢ Disjoint (Finset.filter IsPrimePow (divisors a)) (Finset.filter IsPrimePow (divisors b))\",\n",
    "}\n",
    "print(\"*\"*40 + \"rw variant\" + \"*\"*40)\n",
    "print(modify_theorem_rw(demo_theorem, rw_invocable_inst)) # Equlity-Variant in Fig-1\n",
    "\n",
    "apply_invocable_inst = {\n",
    "    \"init_state\": \"R : Type u_1\\ninst✝ : CommMonoidWithZero R\\nn p : R\\nk a b : ℕ\\nhab : Coprime a b\\n⊢ Disjoint (Finset.filter IsPrimePow (divisors a)) (Finset.filter IsPrimePow (divisors b))\",\n",
    "    \"rule\": \"have hab : a.Coprime b := by apply Nat.coprime_of_mul_modEq_one\",\n",
    "    \"next_state\": \"unsolved goals\\ncase h\\nR : Type u_1\\ninst✝ : CommMonoidWithZero R\\nn p : R\\nk a b : ℕ\\nhab : Coprime a b\\n⊢ a * ?b ≡ 1 [MOD b]\\n\\ncase b\\nR : Type u_1\\ninst✝ : CommMonoidWithZero R\\nn p : R\\nk a b : ℕ\\nhab : Coprime a b\\n⊢ ℕ\"\n",
    "}\n",
    "\n",
    "print(\"*\"*40 + \"apply variant\" + \"*\"*40)\n",
    "print(modify_theorem_apply(demo_theorem, apply_invocable_inst)) # Apply-Variant in Fig-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Mutate \n",
    "In practice, for rw and apply, we mutate the theorems and write variants back to the original Lean file (record the line number of each theorem). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from _logic import filtering_single_goal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for multiple target theorems-case, just change the file2theorem and theorem2output\n",
    "# GEN_MODE = \"rw\"\n",
    "GEN_MODE = \"apply\"\n",
    "file_path = demo_theorem.theorem.file_path.as_posix()\n",
    "file2theorem = {file_path: [demo_theorem]} # path : list of traced theorems\n",
    "theorem2output ={demo_theorem: f\"./outputs/{GEN_MODE}_invocable_theorems_demo.jsonl\"}# target_theorem : path2invocable_theorems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 13.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The file number of lean_corpus is 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# for each traced_file find the related traced_theorems and find the start and end of this theorems\n",
    "# for each target_theorem in this file, modify the theorem and get modified theorems \n",
    "# insert all modified theorems of all traced theorems in this file at once\n",
    "lean_corpus = []\n",
    "test_files = list(file2theorem.items())\n",
    "for traced_file, target_theorems in tqdm.tqdm(test_files, total=len(test_files)):\n",
    "    modifier_blackboard = {}\n",
    "    for target_theorem in target_theorems:\n",
    "        # locate this theorem\n",
    "        theorem_ast = target_theorem.ast\n",
    "        leanfile = theorem_ast.lean_file\n",
    "        start, end = theorem_ast.start, theorem_ast.end\n",
    "        # get the output_file\n",
    "        output_file = theorem2output[target_theorem]\n",
    "        # for this target theorem get its modified version\n",
    "        try:\n",
    "            invocable_theorems = list(load_jsonl(output_file))\n",
    "        except:\n",
    "            print(f\"Error in loading the file {output_file}\")\n",
    "        else:\n",
    "            if GEN_MODE == \"rw\":\n",
    "                filtered_invocable_theorems = filtering_single_goal(invocable_theorems)\n",
    "            elif GEN_MODE == \"apply\":\n",
    "                filtered_invocable_theorems = invocable_theorems\n",
    "            new_theorems = []\n",
    "            for idx, invocable_theorem in enumerate(filtered_invocable_theorems):\n",
    "                insts = list(invocable_theorem.values())[0]\n",
    "                for inst in insts:\n",
    "                    if GEN_MODE == \"rw\":\n",
    "                        new_theorem = modify_theorem_rw(target_theorem, inst)\n",
    "                    elif GEN_MODE == \"apply\":\n",
    "                        try:\n",
    "                            new_theorem = modify_theorem_apply(target_theorem, inst)\n",
    "                        except:\n",
    "                            new_theorem = None\n",
    "                    if new_theorem:\n",
    "                        new_theorems.append(new_theorem)\n",
    "\n",
    "        if not modifier_blackboard.get(target_theorem, 0) and len(new_theorems) > 0:\n",
    "            modifier_blackboard[target_theorem] = {\"start\":start, \"end\": end, \"new_theorems\": new_theorems}\n",
    "\n",
    "    # replace this file all at once\n",
    "    res = dict()\n",
    "    res['file_name'] = traced_file\n",
    "    res['loc'] = dict() # e.g. {theorem_name: [(start, end), (start, end)]}\n",
    "    offset = 0\n",
    "    old_file = '\\n'.join(leanfile.code)\n",
    "    \n",
    "    if len(modifier_blackboard.keys()) != 0:\n",
    "        for target_theorem, modifier in modifier_blackboard.items():\n",
    "            name = target_theorem.theorem.full_name\n",
    "            res['loc'][name] = []\n",
    "            start, end, new_theorems = modifier[\"start\"], modifier[\"end\"], modifier[\"new_theorems\"]\n",
    "            original_theorem = leanfile[start:end]\n",
    "            start = start.line_nb + offset\n",
    "            end = end.line_nb + offset \n",
    "            original_end = end\n",
    "            # get the location of each modified theorems\n",
    "            for idx, new_theorem in enumerate(new_theorems):\n",
    "                if idx == 0:\n",
    "                    theorem_start = end + 3\n",
    "                else:\n",
    "                    theorem_start = end + 2\n",
    "                theorem_end = theorem_start + len(new_theorem.split('\\n')) - 1\n",
    "                end = theorem_end\n",
    "                res['loc'][name].append((theorem_start, theorem_end))\n",
    "            offset += theorem_end - original_end\n",
    "            new_theorem = original_theorem +\"\\n\" + \"\\n\\n\" + \"\\n\\n\".join(new_theorems)\n",
    "            new_file = old_file.replace(original_theorem, new_theorem)\n",
    "            old_file = new_file\n",
    "        res['text'] = new_file\n",
    "    else:\n",
    "        res['text'] = old_file\n",
    "        res['loc'] = ['No variants']\n",
    "    lean_corpus.append(res)\n",
    "\n",
    "print(f\"The file number of lean_corpus is {len(lean_corpus)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_jsonl(lean_corpus, f\"./outputs/{GEN_MODE}_variants_demo_without_verify.jsonl\") # save the modified theorems"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Verify\n",
    "We build the new repo and remove the wrong variants\n",
    "1. We need to clone the Mathlib4.\n",
    "2. Write then Build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clone the mathlib (run once)\n",
    "# !git clone https://github.com/leanprover-community/mathlib4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !cd mathlib4 && git checkout 3c307701fa7e9acbdc0680d7f3b9c9fed9081740"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from verify import lake_build, generate_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Below code is largely modified from verify.py, which is a distributed script used to verify synthesized theorems*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 files in total.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build error\n",
      "lake build the rewrited file Mathlib/Algebra/IsPrimePow.lean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:18<00:00, 18.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lake rebuild the rewrited file Mathlib/Algebra/IsPrimePow.lean\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "mathlib_package_path = \"./mathlib4\"\n",
    "output_path = f\"outputs/verify/{GEN_MODE}\"\n",
    "if not os.path.exists(output_path):\n",
    "    os.makedirs(output_path)\n",
    "\n",
    "PACKAGE_NAME = \"Mathlib\"\n",
    "LIBRARY_ROOT_FILE = os.path.join(mathlib_package_path, PACKAGE_NAME + '.lean')\n",
    "corpus = lean_corpus\n",
    "corpus_path = f\"./outputs/{GEN_MODE}_variants_demo_without_verify.jsonl\"\n",
    "files = list(load_jsonl(corpus_path))\n",
    "print(f\"There are {len(files)} files in total.\")\n",
    "res = []\n",
    "for idx, file in enumerate(tqdm.tqdm(files, total=len(files))):\n",
    "    file_name = file['file_name']\n",
    "    file_path = os.path.join(mathlib_package_path, file_name)\n",
    "    # extract the old content of this file\n",
    "    with open(file_path, \"r\") as f:\n",
    "        old_str = f.read()\n",
    "    # replace the ola content with new content\n",
    "    with open(file_path, \"w\") as f:\n",
    "        f.write(file['text'])\n",
    "    # change the build target to current file\n",
    "    with open(LIBRARY_ROOT_FILE, 'w') as f:\n",
    "        module_name = file_name.replace('/', '.').replace('.lean', '')\n",
    "        f.write(f\"import {module_name}\")\n",
    "    # intialize the result\n",
    "    tmp = dict()\n",
    "    tmp['file_name'] = file_name\n",
    "    tmp['original_text'] = old_str\n",
    "    tmp['text'] = file['text']\n",
    "    tmp['loc'] = file['loc']\n",
    "    tmp['valid_loc'] = []\n",
    "\n",
    "    if file['loc'] != ['No variants']: # if there exists variants in this file\n",
    "        ## lake build the new mathlib project\n",
    "        wd = os.getcwd()\n",
    "        result = lake_build(mathlib_package_path)\n",
    "        os.chdir(wd)\n",
    "        print(f\"lake build the rewrited file {file_name}\")\n",
    "        ## parse the output\n",
    "        if result == None:\n",
    "            tmp['valid_loc'] = [\"subprocess error\"]\n",
    "        elif result == 0:\n",
    "            tmp['valid_loc'] = tmp['loc']\n",
    "            print('successful build')\n",
    "        elif result == -1:\n",
    "            tmp['valid_loc'] = [\"build timeout error\"]\n",
    "        else:\n",
    "            # find the error locations(line numbers)\n",
    "            pattern = fr\"({file_name}):(\\d+):(\\d+): error:\"\n",
    "            errors = re.findall(pattern, result)\n",
    "            if len(errors) == 0:\n",
    "                tmp['valid_loc'] = ['parse error']\n",
    "            else:\n",
    "                error_line_nbs = []\n",
    "                for error in errors:\n",
    "                    _, line_nb, _ = error\n",
    "                    error_line_nbs.append(int(line_nb))\n",
    "                error_line_nbs = sorted(set(error_line_nbs))\n",
    "                error_line_nbs = np.array(error_line_nbs)\n",
    "\n",
    "                # get the locations of all variants\n",
    "                intervals = []\n",
    "                for t, locs in file['loc'].items():\n",
    "                    intervals.extend(locs)\n",
    "                intervals = np.array(intervals)\n",
    "                if len(intervals) != 0:\n",
    "                    # Create a boolean array of the same shape as error_line_nbs, \n",
    "                    # with True at positions where the corresponding element of error_line_nbs is in any interval\n",
    "                    in_interval = (intervals[:, 0, np.newaxis] <= error_line_nbs) & (error_line_nbs <= intervals[:, 1, np.newaxis])\n",
    "                    valid_intervals = intervals[in_interval.sum(axis=1)==0]\n",
    "                    with open(file_path, \"w\") as f:\n",
    "                        f.write(generate_text(file['text'], valid_intervals, intervals))\n",
    "                    ## rebuilt the project if trigger error break\n",
    "                    wd = os.getcwd()\n",
    "                    result = lake_build(mathlib_package_path)\n",
    "                    os.chdir(wd)\n",
    "                    print(f\"lake rebuild the rewrited file {file_name}\")\n",
    "\n",
    "                    if result != 0:\n",
    "                        print(\"rebuild exception\")\n",
    "                        tmp['valid_loc'] = ['rebuild error']\n",
    "                    else:\n",
    "                        tmp['valid_loc'] = valid_intervals.tolist()\n",
    "                else:\n",
    "                    pass\n",
    "    else:\n",
    "        tmp['valid_loc'] = ['No variants']\n",
    "\n",
    "    # write back the original content\n",
    "    with open(file_path, \"w\") as f:\n",
    "        f.write(old_str)\n",
    "    res.append(tmp) \n",
    "save_jsonl(res, os.path.join(output_path, f\"verified_results_{GEN_MODE}_demo.jsonl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Post-processing the verified results\n",
    "for idx, result in enumerate(res):\n",
    "    tmp = dict()\n",
    "    # if not empty or exception\n",
    "    if isinstance(result['valid_loc'], dict):\n",
    "        result['formatted_loc'] = result['loc']\n",
    "    if isinstance(result['valid_loc'], list):\n",
    "        if result['valid_loc'] not in [[\"subprocess error\"], [\"build timeout error\"], [\"parse error\"], [\"rebuild error\"], [\"No variants\"]]:\n",
    "            # for each changed theorem and locs\n",
    "            for ts, locs in result['loc'].items():\n",
    "                tmp[ts] = []\n",
    "                for loc in locs:\n",
    "                    if loc in result['valid_loc']:\n",
    "                        tmp[ts].append(loc)\n",
    "    res[idx]['formatted_loc'] = tmp\n",
    "\n",
    "results = [r for r in res if r['formatted_loc'] and any(r['formatted_loc'].values())]\n",
    "\n",
    "outputs = []\n",
    "for line in res:\n",
    "    tmp = {\n",
    "        'file_name': line['file_name'],\n",
    "        'original_text': line['original_text'],\n",
    "        'text': line['text'],\n",
    "        'valid_loc': line['formatted_loc'],\n",
    "        'loc': line['loc'],\n",
    "        'meta': \"https://github.com/leanprover-community/mathlib4/commit/3c307701fa7e9acbdc0680d7f3b9c9fed9081740\"\n",
    "    }\n",
    "    outputs.append(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_jsonl(outputs, f\"./outputs/synthesized_corpus_{GEN_MODE}_demo.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Just change the GEN_MODE, you can synthesize theorems using different tactics*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Display the variants \n",
    "Now we have synthesized variants for the demo theorems through rw and apply.\n",
    "Let us take a breif look at them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "rw_corpus = list(load_jsonl(f\"./outputs/synthesized_corpus_rw_demo.jsonl\"))\n",
    "apply_corpus = list(load_jsonl(f\"./outputs/synthesized_corpus_apply_demo.jsonl\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*We only synthesize one variant for the demo theorem through rw, which is the example in Fig 1 of our paper*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variant 0\n",
      "example {a b : ℕ} (hab : IsRelPrime a b) :\n",
      "    Disjoint (a.divisors.filter IsPrimePow) (b.divisors.filter IsPrimePow):= by\n",
      "  have hab : a.Coprime b := by rw [←Nat.coprime_iff_isRelPrime] at hab;exact hab\n",
      "  simp only [Finset.disjoint_left, Finset.mem_filter, and_imp, Nat.mem_divisors, not_and]\n",
      "  rintro n han _ha hn hbn _hb -\n",
      "  exact hn.ne_one (Nat.eq_one_of_dvd_coprimes hab han hbn)\n"
     ]
    }
   ],
   "source": [
    "text = rw_corpus[0]['text']\n",
    "valid_locs = rw_corpus[0]['valid_loc']\n",
    "for t, vs in valid_locs.items():\n",
    "    for idx, v in enumerate(vs):\n",
    "        print(f\"Variant {idx}\")\n",
    "        print('\\n'.join(text.split('\\n')[v[0]-1:v[1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*We synthesizes 5 variants for the demo theorem through apply, which includes the example in Fig 1*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variant 0\n",
      "example {a b : ℕ} (g : b ∈ []) :\n",
      "    Disjoint (a.divisors.filter IsPrimePow) (b.divisors.filter IsPrimePow):= by\n",
      "  have hab : a.Coprime b := by apply List.forall_mem_nil; assumption\n",
      "  simp only [Finset.disjoint_left, Finset.mem_filter, and_imp, Nat.mem_divisors, not_and]\n",
      "  rintro n han _ha hn hbn _hb -\n",
      "  exact hn.ne_one (Nat.eq_one_of_dvd_coprimes hab han hbn)\n",
      "Variant 1\n",
      "example {a b : ℕ} (r : ℕ) (h : a * r ≡ 1 [MOD b]) :\n",
      "    Disjoint (a.divisors.filter IsPrimePow) (b.divisors.filter IsPrimePow):= by\n",
      "  have hab : a.Coprime b := by apply Nat.coprime_of_mul_modEq_one<;> assumption\n",
      "  simp only [Finset.disjoint_left, Finset.mem_filter, and_imp, Nat.mem_divisors, not_and]\n",
      "  rintro n han _ha hn hbn _hb -\n",
      "  exact hn.ne_one (Nat.eq_one_of_dvd_coprimes hab han hbn)\n",
      "Variant 2\n",
      "example {a b : ℕ} (s : Set ℕ) (h : Set.Subsingleton s) (d : a ∈ s) (d : b ∈ s) (d : a ≠ b) :\n",
      "    Disjoint (a.divisors.filter IsPrimePow) (b.divisors.filter IsPrimePow):= by\n",
      "  have hab : a.Coprime b := by apply Set.Subsingleton.pairwise<;> assumption\n",
      "  simp only [Finset.disjoint_left, Finset.mem_filter, and_imp, Nat.mem_divisors, not_and]\n",
      "  rintro n han _ha hn hbn _hb -\n",
      "  exact hn.ne_one (Nat.eq_one_of_dvd_coprimes hab han hbn)\n",
      "Variant 3\n",
      "example {a b : ℕ} (y : 1 ∈ ⋂ i, Eq i) :\n",
      "    Disjoint (a.divisors.filter IsPrimePow) (b.divisors.filter IsPrimePow):= by\n",
      "  have hab : a.Coprime b := by apply Set.iInter_subset; assumption\n",
      "  simp only [Finset.disjoint_left, Finset.mem_filter, and_imp, Nat.mem_divisors, not_and]\n",
      "  rintro n han _ha hn hbn _hb -\n",
      "  exact hn.ne_one (Nat.eq_one_of_dvd_coprimes hab han hbn)\n",
      "Variant 4\n",
      "example {a b : ℕ} (h : 0 = 1) :\n",
      "    Disjoint (a.divisors.filter IsPrimePow) (b.divisors.filter IsPrimePow):= by\n",
      "  have hab : a.Coprime b := by apply eq_of_zero_eq_one; assumption\n",
      "  simp only [Finset.disjoint_left, Finset.mem_filter, and_imp, Nat.mem_divisors, not_and]\n",
      "  rintro n han _ha hn hbn _hb -\n",
      "  exact hn.ne_one (Nat.eq_one_of_dvd_coprimes hab han hbn)\n"
     ]
    }
   ],
   "source": [
    "text = apply_corpus[0]['text']\n",
    "valid_locs = apply_corpus[0]['valid_loc']\n",
    "for t, vs in valid_locs.items():\n",
    "    for idx, v in enumerate(vs):\n",
    "        print(f\"Variant {idx}\")\n",
    "        print('\\n'.join(text.split('\\n')[v[0]-1:v[1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Construct the training data\n",
    "Since we have synthesized variants for target theorem and recorded their locations. We can construct training data for:\n",
    "1. Continual Pretrain\n",
    "2. Supervised Fine-tuning\n",
    "   \n",
    "To retrieve the state-tactic pairs, we need to\n",
    "1. Write back all variants to original repo.\n",
    "2. Use Leandojo to trace this repo.\n",
    "3. Parse the resulting ASTs to extract the additional state-tactic pairs.\n",
    "   \n",
    "*For the extract stage in 3., we provide a multi-process implementation in the extract_state_tactic.py*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "leandojo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
